{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "import os\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://tfhub.dev/google/imagenet/resnet_v2_50/feature_vector/1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"https://tfhub.dev/google/imagenet/resnet_v2_50/feature_vector/1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self,n_classes,n_views, module_path, v_cands, batch_size, learning_rate = 0.05, decay_factor = 0.9, decay_steps = 1e100, weight_decay = 0.005):\n",
    "        self.n_classes = n_classes\n",
    "        self.n_views = n_views\n",
    "        self.module_path = module_path\n",
    "        self.v_cands = np.load(v_cands)\n",
    "        self.batch_size = batch_size\n",
    "        self.n_objects = int(batch_size/n_views)\n",
    "        self.indexes = self.indexes_to_gather(self.v_cands,batch_size,n_views)\n",
    "        self.n_cands = self.v_cands.shape[0]\n",
    "        self.weight_decay = weight_decay\n",
    "        self.decay_steps = decay_steps\n",
    "        self.decay_factor = decay_factor\n",
    "        self.learning_rate = learning_rate\n",
    "        self.init_global_step()\n",
    "        \n",
    "    def indexes_to_gather(self,v_cands,batch_size,n_views):\n",
    "        \n",
    "        # n_objects,n_views_per_obj,n_views,n_classes+1\n",
    "        n_objects = int(batch_size/n_views)\n",
    "        \n",
    "        candidate_indexes = []\n",
    "        \n",
    "        for obj in range(n_objects):\n",
    "            obj_cand = []\n",
    "            for i in range(v_cands.shape[0]):\n",
    "                v_cand = []\n",
    "                for j in range(v_cands.shape[1]):\n",
    "                    v_cand.append([obj,j,v_cands[i,j]])\n",
    "                obj_cand.append(v_cand)\n",
    "            candidate_indexes.append(obj_cand)\n",
    "            \n",
    "        #tensor of shape [n_objs, n_cands, n_views,3]\n",
    "        return tf.convert_to_tensor(candidate_indexes, tf.int32)\n",
    "    \n",
    "    def init_global_step(self):\n",
    "        # DON'T forget to add the global step tensor to the tensorflow trainer\n",
    "        with tf.variable_scope('global_step'):\n",
    "            self.global_step_tensor = tf.Variable(0, trainable=False, name='global_step')\n",
    "        \n",
    "    def build_model(self):\n",
    "\n",
    "        \n",
    "        module = hub.Module(self.module_path)\n",
    "        self.height, self.width =  hub.get_expected_image_size(module)\n",
    "        self.input = tf.placeholder(tf.float32, [None, self.height, self.width, 3])\n",
    "        self.labels = tf.placeholder(tf.int32,[None])\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.hidden_layer = module(self.input)\n",
    "        self.logits = tf.layers.dense(self.hidden_layer, (self.n_classes+1)*self.n_views, activation= None)\n",
    "        \n",
    "        #n_objects_per_batch,n_views_in_batch,n_views_logits,n_classes+1\n",
    "        self.probs = tf.nn.softmax(tf.reshape(self.logits, [self.n_objects,self.n_views,self.n_views,self.n_classes+1]), axis = -1)\n",
    "        self.log_p = tf.math.log(self.probs)\n",
    "        print(self.log_p)\n",
    "        self.scores = self.log_p[...,:-1] - tf.tile(self.log_p[...,-1:],[1,1,1,self.n_classes])\n",
    "        \n",
    "        \"\"\"\n",
    "        Calculate the score for each view order candidate\n",
    "        Determine best view order candidate\n",
    "        \n",
    "        Create a gathering tensor to hook the scores for groundtruth label y\n",
    "        Last dimension of the gathering tensor is [object index, input image index, view candidate, label]\n",
    "        \n",
    "        We gather these values for every candidate, and create a matrix C of shape [n_objects,n_cands]\n",
    "        where C[i,j] is the final score for object i and view order candidate j\n",
    "        \n",
    "        Finally, we gather the best indexes in gathering tensor for calculating the loss\n",
    "        \"\"\"\n",
    "        tiled = tf.tile(tf.reshape(self.labels,[self.n_objects,-1]),[1,self.n_cands])\n",
    "        tiled = tf.reshape(tiled,[self.n_objects,self.n_cands,self.n_views, 1])\n",
    "        #tensor of shape [n_objs, n_cands, n_views,4]\n",
    "        self.gather_candidate_scores = tf.concat([self.indexes,tiled], axis = -1)\n",
    "        # candidates[i,j] is the score for object i and view order candidate j\n",
    "        self.candidate_scores = tf.reduce_sum(tf.gather_nd(self.scores,self.gather_candidate_scores), axis = -1)\n",
    "        \n",
    "        best_candidates = tf.reshape(tf.argmin(self.candidate_scores, -1),[self.n_objects,1])\n",
    "        # pair [[0,cand_0],[1,cand_1],...]\n",
    "        best_candidates = tf.concat([tf.reshape(tf.range(0,self.n_objects, dtype = tf.int64),[self.n_objects,1]),best_candidates], axis = -1)\n",
    "        \n",
    "        \"\"\"\n",
    "        Calculate loss considering best order candidate\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        var_list = tf.trainable_variables()\n",
    "        # Train op\n",
    "        with tf.name_scope(\"train\"):\n",
    "            #loss function\n",
    "            with tf.name_scope(\"loss\"):\n",
    "                self.labels = tf.reshape(self.labels,[-1,self.n_views])[:,0]\n",
    "                #Calculate cross-entropy loss of best view candidates\n",
    "                #shape [n_objects,n_views,3]\n",
    "                gather_candidate_log_prob = tf.gather_nd(self.gather_candidate_scores,best_candidates)\n",
    "                self.loss = -tf.reduce_sum(tf.gather_nd(self.log_p,gather_candidate_log_prob))\n",
    "                #Sum the loss of i_view\n",
    "                self.loss -= self.log_p[:,:,:,-1]\n",
    "                #Discount the loss of i_view for the best view point\n",
    "                discount_iview = tf.concat([(self.n_classes+1)*tf.ones([self.n_objects, self.n_views,1], dtype = tf.int32),gather_candidate_log_prob[...,:-1]], axis = -1)\n",
    "                self.discount_iview = discount_iview\n",
    "                self.loss += tf.reduce_sum(tf.gather_nd(self.log_p,discount_iview))\n",
    "\n",
    "                \n",
    "                #l2 loss (improves the performance)\n",
    "                for var in var_list:\n",
    "                    self.loss += tf.nn.l2_loss(var)*self.weight_decay\n",
    "                    \n",
    "                self.predictions = self.select_best(self.logits)\n",
    "                \n",
    "            \n",
    "            # Get gradients of all trainable variables\n",
    "            gradients = tf.gradients(self.loss, var_list)\n",
    "            gradients = list(zip(gradients, var_list))\n",
    "            \n",
    "            # learning rate\n",
    "            decay_steps = 10\n",
    "            self.learning_rate = tf.train.exponential_decay(self.learning_rate,\n",
    "                                                            self.global_step_tensor,\n",
    "                                                            self.decay_steps,\n",
    "                                                            self.decay_factor,\n",
    "                                                            staircase=True)\n",
    "            \n",
    "            # setting different training ops for each part of the network\n",
    "            # we set a smaller lr for the layers in the middle\n",
    "            var_list_bottom = [self.logits]\n",
    "            gradients = tf.gradients(self.loss, var_list)\n",
    "            \"\"\"\n",
    "            bottom_variables = \n",
    "            grads_bottom = gradients[:-self.VARS_TO_TRAIN]\n",
    "            grads_top = gradients[-self.VARS_TO_TRAIN:]\n",
    "            train_op_bottom = optimizer_bottom.apply_gradients(zip(grads_bottom, var_list_bottom), global_step = self.global_step_tensor)\n",
    "            train_op_top = optimizer_top.apply_gradients(zip(grads_top, var_list))\n",
    "            self.train_step = tf.group(train_op_bottom, train_op_top)\n",
    "            \"\"\"\n",
    "    def select_best(self,fc8):\n",
    "        #shape batch_size x P matrix\n",
    "        fc8 =  tf.reshape(fc8,[-1, self.n_views, self.n_classes + 1])\n",
    "        #apply softmax on the rows of the P matrix\n",
    "        fc8 = tf.log(tf.nn.softmax(fc8,axis = -1))\n",
    "        self.softmax_fc8 = fc8\n",
    "        #divide all probs by the probability of incorrect view (shape (batch_size,view_num,classes_num))\n",
    "        i_view_probability_to_sub = tf.tile(tf.expand_dims(fc8[...,-1],-1),[1,1,self.n_classes])\n",
    "        fc8 = fc8[...,:-1]\n",
    "        score = fc8 - i_view_probability_to_sub\n",
    "        self.score1 = score\n",
    "        # score per image per object\n",
    "        score =  tf.reshape(score,[self.n_objects,self.n_views, self.n_views, self.n_classes])\n",
    "        self.score = tf.reduce_sum(tf.reduce_max(score, axis = -2),axis = -2)\n",
    "        best_classes = tf.argmax(self.score,axis = -1)\n",
    "        return tf.cast(best_classes,dtype = tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataloader:\n",
    "    \n",
    "    def __init__(self,\n",
    "                 sess,\n",
    "                 config,\n",
    "                 shuffle_buffer_size = 1000,\n",
    "                 prefetch_buffer_size = 1000,\n",
    "                 seed = 42):\n",
    "        tf.set_random_seed(seed)\n",
    "        \n",
    "        self.sess = ses\n",
    "        self.data_dir = config[\"data_dir\"]\n",
    "        self.shuffe_buffer_size = shuffle_buffer_size\n",
    "        self.prefetch_buffer_size = prefetch_buffer_size\n",
    "    \n",
    "    def get_image_path(self):\n",
    "        train_dir = self.data_dir + 'train/'\n",
    "        test_dir = self.data_dir + 'test/'\n",
    "        \n",
    "        if not os.path.isdir(train_dir) or not os.path.isdir(test_dir):\n",
    "            \n",
    "class Trainer:\n",
    "    \n",
    "    def __init__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0312 20:07:38.693769 12988 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Log_6:0\", shape=(4, 20, 20, 41), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "model = Model(40,20,\"https://tfhub.dev/google/imagenet/mobilenet_v2_050_96/feature_vector/2\",\"vcand_case2.npy\",80)\n",
    "model.build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0305 20:38:58.444226  3300 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "module = hub.Module(\"https://tfhub.dev/google/imagenet/mobilenet_v2_050_96/feature_vector/2\", trainable = True)\n",
    "height, width = hub.get_expected_image_size(module)\n",
    "images = np.random.rand(3,height,width,3)  # A batch of images with shape [batch_size, height, width, 3].\n",
    "features = module(images)  # Features with shape [batch_size, num_features].\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-7-5ecd8d224286>:1: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0305 20:39:27.151699  3300 deprecation.py:323] From <ipython-input-7-5ecd8d224286>:1: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'dense/BiasAdd:0' shape=(3, 1028) dtype=float32>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.layers.dense(features, 1028)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow._api.v1.keras.layers' has no attribute 'dense'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-dd33ef8ccd16>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1028\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow._api.v1.keras.layers' has no attribute 'dense'"
     ]
    }
   ],
   "source": [
    "tf.keras.layers.dense(features,1028)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'run'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-765f14f11663>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mfeatures\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'run'"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(features, feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
