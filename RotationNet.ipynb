{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"https://tfhub.dev/google/imagenet/resnet_v2_50/feature_vector/1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self,n_classes,n_views, module_path, v_cands, batch_size):\n",
    "        self.n_classes = n_classes\n",
    "        self.n_views = n_views\n",
    "        self.module_path = module_path\n",
    "        self.v_cands = np.load(v_cands)\n",
    "        self.batch_size = batch_size\n",
    "        self.n_objects = int(batch_size/n_views)\n",
    "        self.indexes = self.indexes_to_gather(self.v_cands,batch_size,n_views)\n",
    "        self.n_cands = self.v_cands.shape[0]\n",
    "        \n",
    "    def indexes_to_gather(self,v_cands,batch_size,n_views):\n",
    "        \n",
    "        # n_objects,n_views_per_obj,n_views,n_classes+1\n",
    "        n_objects = int(batch_size/n_views)\n",
    "        \n",
    "        candidate_indexes = []\n",
    "        \n",
    "        for obj in range(n_objects):\n",
    "            obj_cand = []\n",
    "            for i in range(v_cands.shape[0]):\n",
    "                v_cand = []\n",
    "                for j in range(v_cands.shape[1]):\n",
    "                    v_cand.append([obj,j,v_cands[i,j]])\n",
    "                obj_cand.append(v_cand)\n",
    "            candidate_indexes.append(obj_cand)\n",
    "            \n",
    "        #tensor of shape [n_objs, n_cands, n_views,3]\n",
    "        return tf.convert_to_tensor(candidate_indexes, tf.int32)\n",
    "        \n",
    "        \n",
    "    def build_model(self):\n",
    "        self.input = tf.placeholder(tf.float32, [None, height, width, 3])\n",
    "        self.labels = tf.placeholder(tf.int32,[None])\n",
    "        \n",
    "        module = hub.Module(self.module_path)\n",
    "        self.height, self.width =  hub.get_expected_image_size(module)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        self.hidden_layer = module(self.input)\n",
    "        self.logits = tf.layers.dense(self.hidden_layer, (self.n_classes+1)*self.n_views, activation= None)\n",
    "        \n",
    "        #n_objects_per_batch,n_views_in_batch,n_views_logits,n_classes+1\n",
    "        self.probs = tf.nn.softmax(tf.reshape(self.logits, [self.n_objects,self.n_views,self.n_views,self.n_classes+1]), axis = -1)\n",
    "        self.log_p = tf.math.log(self.probs)\n",
    "        print(self.log_p)\n",
    "        self.scores = self.log_p[...,:-1] - tf.tile(self.log_p[...,-1:],[1,1,1,self.n_classes])\n",
    "        \n",
    "        \"\"\"\n",
    "        Calculate the score for each view order candidate\n",
    "        Determine best view order candidate\n",
    "        \n",
    "        Create a gathering tensor to hook the scores for groundtruth label y\n",
    "        Last dimension of the gathering tensor is [object index, input image index, view candidate, label]\n",
    "        \n",
    "        We gather these values for every candidate, and create a matrix C of shape [n_objects,n_cands]\n",
    "        where C[i,j] is the final score for object i and view order candidate j\n",
    "        \n",
    "        Finally, we gather the best indexes in gathering tensor for calculating the loss\n",
    "        \"\"\"\n",
    "        tiled = tf.tile(tf.reshape(self.labels,[self.n_objects,-1]),[1,self.n_cands])\n",
    "        tiled = tf.reshape(tiled,[self.n_objects,self.n_cands,self.n_views, 1])\n",
    "        #tensor of shape [n_objs, n_cands, n_views,4]\n",
    "        self.gather_candidate_scores = tf.concat([self.indexes,tiled], axis = -1)\n",
    "        # candidates[i,j] is the score for object i and view order candidate j\n",
    "        self.candidate_scores = tf.reduce_sum(tf.gather_nd(self.scores,self.gather_candidate_scores), axis = -1)\n",
    "        \n",
    "        best_candidates = tf.reshape(tf.argmin(self.candidate_scores, -1),[self.n_objects,1])\n",
    "        # pair [[0,cand_0],[1,cand_1],...]\n",
    "        best_candidates = tf.concat([tf.reshape(tf.range(0,self.n_objects, dtype = tf.int64),[self.n_objects,1]),best_candidates], axis = -1)\n",
    "        \n",
    "        \"\"\"\n",
    "        Calculate loss considering best order candidate\n",
    "        \"\"\"\n",
    "        \n",
    "        #Calculate cross-entropy loss of best view candidates\n",
    "        #shape [n_objects,n_views,3]\n",
    "        gather_candidate_log_prob = tf.gather_nd(self.gather_candidate_scores,best_candidates)\n",
    "        self.loss = -tf.reduce_sum(tf.gather_nd(self.log_p,gather_candidate_log_prob))\n",
    "        #Sum the loss of i_view\n",
    "        self.loss -= self.log_p[:,:,:,-1]\n",
    "        #Discount the loss of i_view for the best view point\n",
    "        discount_iview = tf.concat([(self.n_classes+1)*tf.ones([self.n_objects, self.n_views,1], dtype = tf.int32),gather_candidate_log_prob[...,:-1]], axis = -1)\n",
    "        self.discount_iview = discount_iview\n",
    "        self.loss += tf.reduce_sum(tf.gather_nd(self.log_p,discount_iview))\n",
    "        \n",
    "        \n",
    "        ## for testing\n",
    "        self.discount_iview = discount_iview\n",
    "        self.gather_candidate_log_prob = gather_candidate_log_prob\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = tf.ones((4, 20, 21, 41))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'concat_18:0' shape=(4, 20, 5) dtype=int32>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.discount_iview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0306 22:41:52.810515  3300 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Log_12:0\", shape=(4, 20, 20, 41), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "model = Model(40,20,\"https://tfhub.dev/google/imagenet/mobilenet_v2_050_96/feature_vector/2\",\"vcand_case2.npy\",80)\n",
    "model.build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0305 20:38:58.444226  3300 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "module = hub.Module(\"https://tfhub.dev/google/imagenet/mobilenet_v2_050_96/feature_vector/2\", trainable = True)\n",
    "height, width = hub.get_expected_image_size(module)\n",
    "images = np.random.rand(3,height,width,3)  # A batch of images with shape [batch_size, height, width, 3].\n",
    "features = module(images)  # Features with shape [batch_size, num_features].\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-7-5ecd8d224286>:1: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0305 20:39:27.151699  3300 deprecation.py:323] From <ipython-input-7-5ecd8d224286>:1: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'dense/BiasAdd:0' shape=(3, 1028) dtype=float32>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.layers.dense(features, 1028)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow._api.v1.keras.layers' has no attribute 'dense'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-dd33ef8ccd16>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1028\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow._api.v1.keras.layers' has no attribute 'dense'"
     ]
    }
   ],
   "source": [
    "tf.keras.layers.dense(features,1028)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'run'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-765f14f11663>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mfeatures\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'run'"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(features, feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
